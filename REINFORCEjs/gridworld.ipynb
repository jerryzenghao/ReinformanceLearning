{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from environment import GridWorld\n",
    "from agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_matrix = np.zeros((10,10))\n",
    "reward_matrix[3,3] = -1\n",
    "reward_matrix[4,5] = -1\n",
    "reward_matrix[4,6] = -1\n",
    "reward_matrix[5,5] = 1\n",
    "reward_matrix[5,6] = -1\n",
    "reward_matrix[5,8] = -1\n",
    "reward_matrix[6,8] = -1\n",
    "reward_matrix[7,3] = -1\n",
    "reward_matrix[7,5] = -1\n",
    "reward_matrix[7,6] = -1\n",
    "env = GridWorld(reward_matrix)\n",
    "agt = DPAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0., nan, nan, nan, nan,  0., nan, nan, nan,  0.],\n       [ 0.,  0.,  0., -1., nan,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0., nan, -1., -1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0., nan,  1., -1.,  0., -1.,  0.],\n       [ 0.,  0.,  0.,  0., nan,  0.,  0.,  0., -1.,  0.],\n       [ 0.,  0.,  0., -1., nan, -1., -1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "env.reward_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3, 5)\n(4, 6)\n(5, 5)\n(4, 5)\n"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(env.get_next_state((4,5),i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Policy Evaluation:\n [[-0.06 -0.05 -0.04 -0.05 -0.08 -0.11 -0.09 -0.09 -0.1  -0.14]\n [-0.09 -0.05 -0.05 -0.06 -0.1  -0.2  -0.11 -0.09 -0.11 -0.2 ]\n [-0.19   nan   nan   nan   nan -0.58   nan   nan   nan -0.42]\n [-0.34 -0.61 -1.26 -2.88   nan -1.22 -1.48 -1.19 -1.   -0.78]\n [-0.35 -0.5  -0.84 -1.33   nan -2.15 -2.67 -1.62 -1.47 -1.18]\n [-0.33 -0.42 -0.63 -0.88   nan  0.94 -2.2  -1.87 -2.74 -1.68]\n [-0.32 -0.42 -0.67 -1.07   nan -1.02 -1.71 -1.76 -2.71 -1.67]\n [-0.32 -0.45 -0.87 -2.13   nan -2.73 -2.64 -1.54 -1.42 -1.18]\n [-0.3  -0.38 -0.6  -0.95 -0.86 -1.3  -1.32 -1.02 -0.9  -0.83]\n [-0.29 -0.34 -0.48 -0.64 -0.71 -0.87 -0.89 -0.79 -0.72 -0.7 ]]\n"
    }
   ],
   "source": [
    "agt.policy_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Policy Evaluation:\n [[-0.06 -0.05 -0.04 -0.05 -0.08 -0.11 -0.09 -0.09 -0.1  -0.14]\n [-0.09 -0.05 -0.05 -0.06 -0.1  -0.2  -0.11 -0.09 -0.11 -0.2 ]\n [-0.19   nan   nan   nan   nan -0.58   nan   nan   nan -0.42]\n [-0.34 -0.61 -1.26 -2.88   nan -1.22 -1.48 -1.19 -1.   -0.78]\n [-0.35 -0.5  -0.84 -1.33   nan -2.15 -2.67 -1.62 -1.47 -1.18]\n [-0.33 -0.42 -0.63 -0.88   nan  0.94 -2.2  -1.87 -2.74 -1.68]\n [-0.32 -0.42 -0.67 -1.07   nan -1.02 -1.71 -1.76 -2.71 -1.67]\n [-0.32 -0.45 -0.87 -2.13   nan -2.73 -2.64 -1.54 -1.42 -1.18]\n [-0.3  -0.38 -0.6  -0.95 -0.86 -1.3  -1.32 -1.02 -0.9  -0.83]\n [-0.29 -0.34 -0.48 -0.64 -0.71 -0.87 -0.89 -0.79 -0.72 -0.7 ]]\nPolicy Evaluation:\n [[-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.     nan   nan   nan   nan -0.     nan   nan   nan -0.  ]\n [-0.   -0.   -0.   -1.     nan -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.     nan -0.1  -1.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.     nan  1.   -0.1  -0.   -1.   -0.  ]\n [-0.   -0.   -0.   -0.     nan  0.9   0.81 -0.   -1.   -0.  ]\n [-0.   -0.   -0.   -1.     nan -0.19 -1.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]]\nPolicy Evaluation:\n [[-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.     nan   nan   nan   nan -0.     nan   nan   nan -0.  ]\n [-0.   -0.   -0.   -1.     nan -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.     nan -0.1  -1.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.     nan  1.   -0.1  -0.   -1.   -0.  ]\n [-0.   -0.   -0.   -0.     nan  0.9   0.81  0.73 -0.75 -0.  ]\n [-0.   -0.   -0.   -1.     nan -0.19 -0.27  0.28  0.12  0.05]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.    0.09  0.06  0.04]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.    0.04  0.04  0.03]]\nPolicy Evaluation:\n [[-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.     nan   nan   nan   nan -0.     nan   nan   nan -0.  ]\n [-0.   -0.   -0.   -1.     nan -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.     nan -0.1  -1.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.     nan  1.   -0.1   0.66 -0.41 -0.  ]\n [-0.   -0.   -0.   -0.     nan  0.9   0.81  0.73 -0.34  0.48]\n [-0.   -0.   -0.   -1.     nan -0.19 -0.27  0.66  0.59  0.53]\n [-0.   -0.   -0.   -0.   -0.   -0.    0.53  0.59  0.53  0.48]\n [-0.   -0.   -0.   -0.   -0.   -0.    0.48  0.53  0.48  0.43]]\nPolicy Evaluation:\n [[-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.  ]\n [-0.     nan   nan   nan   nan  0.03   nan   nan   nan -0.  ]\n [-0.   -0.   -0.   -1.     nan  0.07  0.14  0.26  0.16 -0.  ]\n [-0.   -0.   -0.   -0.     nan -0.1  -0.67  0.59  0.29  0.21]\n [-0.   -0.   -0.   -0.     nan  1.   -0.1   0.66 -0.41  0.43]\n [-0.   -0.   -0.   -0.     nan  0.9   0.81  0.73 -0.34  0.48]\n [-0.   -0.   -0.   -1.     nan -0.19 -0.27  0.66  0.59  0.53]\n [-0.   -0.   -0.   -0.   -0.    0.48  0.53  0.59  0.53  0.48]\n [-0.   -0.   -0.   -0.   -0.    0.43  0.48  0.53  0.48  0.43]]\nPolicy Evaluation:\n [[-0.   -0.   -0.   -0.   -0.   -0.   -0.    0.05  0.06  0.05]\n [-0.   -0.   -0.   -0.   -0.    0.35  0.31  0.13  0.08  0.15]\n [-0.     nan   nan   nan   nan  0.39   nan   nan   nan  0.26]\n [-0.   -0.   -0.   -1.     nan  0.43  0.48  0.53  0.48  0.35]\n [-0.    0.    0.    0.     nan -0.1  -0.47  0.59  0.53  0.39]\n [-0.    0.    0.    0.     nan  1.   -0.1   0.66 -0.41  0.43]\n [ 0.    0.01  0.01 -0.     nan  0.9   0.81  0.73 -0.34  0.48]\n [ 0.01  0.02  0.03 -0.93   nan -0.19 -0.27  0.66  0.59  0.53]\n [ 0.01  0.02  0.07  0.2   0.43  0.48  0.53  0.59  0.53  0.48]\n [ 0.   -0.   -0.    0.18  0.39  0.43  0.48  0.53  0.48  0.43]]\nPolicy Evaluation:\n [[-0.   -0.   -0.    0.24  0.27  0.31  0.28  0.25  0.28  0.31]\n [-0.   -0.   -0.    0.14  0.31  0.35  0.31  0.28  0.31  0.35]\n [-0.     nan   nan   nan   nan  0.39   nan   nan   nan  0.39]\n [-0.    0.19  0.21 -0.81   nan  0.43  0.48  0.53  0.48  0.43]\n [ 0.19  0.21  0.23  0.21   nan -0.1  -0.47  0.59  0.53  0.48]\n [ 0.21  0.23  0.25  0.23   nan  1.   -0.1   0.66 -0.41  0.43]\n [ 0.23  0.25  0.28  0.25   nan  0.9   0.81  0.73 -0.34  0.48]\n [ 0.25  0.28  0.31 -0.65   nan -0.19 -0.27  0.66  0.59  0.53]\n [ 0.28  0.31  0.35  0.39  0.43  0.48  0.53  0.59  0.53  0.48]\n [ 0.25  0.28  0.31  0.35  0.39  0.43  0.48  0.53  0.48  0.43]]\nPolicy Evaluation:\n [[ 0.12  0.15  0.25  0.28  0.31  0.35  0.31  0.28  0.31  0.35]\n [ 0.14  0.12  0.28  0.31  0.35  0.39  0.35  0.31  0.35  0.39]\n [ 0.17   nan   nan   nan   nan  0.43   nan   nan   nan  0.43]\n [ 0.19  0.21  0.23 -0.79   nan  0.48  0.53  0.59  0.53  0.48]\n [ 0.21  0.23  0.25  0.23   nan -0.   -0.41  0.66  0.59  0.53]\n [ 0.23  0.25  0.28  0.25   nan  1.11 -0.    0.73 -0.34  0.48]\n [ 0.25  0.28  0.31  0.28   nan  1.    0.9   0.81 -0.27  0.53]\n [ 0.28  0.31  0.35 -0.61   nan -0.1  -0.19  0.73  0.66  0.59]\n [ 0.31  0.35  0.39  0.43  0.48  0.53  0.59  0.66  0.59  0.53]\n [ 0.28  0.31  0.35  0.39  0.43  0.48  0.53  0.59  0.53  0.48]]\nPolicy Evaluation:\n [[ 0.22  0.25  0.27  0.31  0.34  0.38  0.34  0.31  0.34  0.38]\n [ 0.16  0.27  0.31  0.34  0.38  0.42  0.38  0.34  0.38  0.42]\n [ 0.18   nan   nan   nan   nan  0.46   nan   nan   nan  0.46]\n [ 0.2   0.22  0.25 -0.78   nan  0.52  0.57  0.64  0.57  0.52]\n [ 0.22  0.25  0.27  0.25   nan  0.08 -0.36  0.71  0.64  0.57]\n [ 0.25  0.27  0.31  0.27   nan  1.2   0.08  0.79 -0.29  0.52]\n [ 0.27  0.31  0.34  0.31   nan  1.08  0.97  0.87 -0.21  0.57]\n [ 0.31  0.34  0.38 -0.58   nan -0.03 -0.13  0.79  0.71  0.64]\n [ 0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.71  0.64  0.57]\n [ 0.31  0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.57  0.52]]\nPolicy Evaluation:\n [[ 0.22  0.25  0.27  0.31  0.34  0.38  0.34  0.31  0.34  0.38]\n [ 0.25  0.27  0.31  0.34  0.38  0.42  0.38  0.34  0.38  0.42]\n [ 0.18   nan   nan   nan   nan  0.46   nan   nan   nan  0.46]\n [ 0.2   0.22  0.25 -0.78   nan  0.52  0.57  0.64  0.57  0.52]\n [ 0.22  0.25  0.27  0.25   nan  0.08 -0.36  0.71  0.64  0.57]\n [ 0.25  0.27  0.31  0.27   nan  1.2   0.08  0.79 -0.29  0.52]\n [ 0.27  0.31  0.34  0.31   nan  1.08  0.97  0.87 -0.21  0.57]\n [ 0.31  0.34  0.38 -0.58   nan -0.03 -0.13  0.79  0.71  0.64]\n [ 0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.71  0.64  0.57]\n [ 0.31  0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.57  0.52]]\nPolicy Evaluation:\n [[ 0.22  0.25  0.27  0.31  0.34  0.38  0.34  0.31  0.34  0.38]\n [ 0.25  0.27  0.31  0.34  0.38  0.42  0.38  0.34  0.38  0.42]\n [ 0.22   nan   nan   nan   nan  0.46   nan   nan   nan  0.46]\n [ 0.2   0.22  0.25 -0.78   nan  0.52  0.57  0.64  0.57  0.52]\n [ 0.22  0.25  0.27  0.25   nan  0.08 -0.36  0.71  0.64  0.57]\n [ 0.25  0.27  0.31  0.27   nan  1.2   0.08  0.79 -0.29  0.52]\n [ 0.27  0.31  0.34  0.31   nan  1.08  0.97  0.87 -0.21  0.57]\n [ 0.31  0.34  0.38 -0.58   nan -0.03 -0.13  0.79  0.71  0.64]\n [ 0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.71  0.64  0.57]\n [ 0.31  0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.57  0.52]]\nPolicy Evaluation:\n [[ 0.22  0.25  0.27  0.31  0.34  0.38  0.34  0.31  0.34  0.38]\n [ 0.25  0.27  0.31  0.34  0.38  0.42  0.38  0.34  0.38  0.42]\n [ 0.22   nan   nan   nan   nan  0.46   nan   nan   nan  0.46]\n [ 0.2   0.22  0.25 -0.78   nan  0.52  0.57  0.64  0.57  0.52]\n [ 0.22  0.25  0.27  0.25   nan  0.08 -0.36  0.71  0.64  0.57]\n [ 0.25  0.27  0.31  0.27   nan  1.2   0.08  0.79 -0.29  0.52]\n [ 0.27  0.31  0.34  0.31   nan  1.08  0.97  0.87 -0.21  0.57]\n [ 0.31  0.34  0.38 -0.58   nan -0.03 -0.13  0.79  0.71  0.64]\n [ 0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.71  0.64  0.57]\n [ 0.31  0.34  0.38  0.42  0.46  0.52  0.57  0.64  0.57  0.52]]\nPolicy stable.\n"
    }
   ],
   "source": [
    "agt.policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[[0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.5, 0.5],\n  [0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0]],\n [[0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.5, 0.0, 0.5],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 0.0, 1.0, 0.0]],\n [[1.0, 0.0, 0.0, 0.0],\n  None,\n  None,\n  None,\n  None,\n  [0.0, 0.0, 1.0, 0.0],\n  None,\n  None,\n  None,\n  [0.0, 0.0, 1.0, 0.0]],\n [[0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.5, 0.5],\n  None,\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.5, 0.5],\n  [0.0, 0.0, 0.5, 0.5]],\n [[0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.5, 0.5],\n  None,\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.0, 0.0, 1.0]],\n [[0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.5, 0.5],\n  None,\n  [0.25, 0.25, 0.25, 0.25],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.5, 0.0, 0.5, 0.0]],\n [[0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 0.0, 1.0],\n  None,\n  [1.0, 0.0, 0.0, 0.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.0, 1.0, 0.0]],\n [[0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.5, 0.5, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  [0.0, 0.0, 1.0, 0.0],\n  None,\n  [1.0, 0.0, 0.0, 0.0],\n  [1.0, 0.0, 0.0, 0.0],\n  [1.0, 0.0, 0.0, 0.0],\n  [0.0, 0.0, 0.0, 1.0],\n  [0.0, 0.0, 0.0, 1.0]],\n [[0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [0.0, 1.0, 0.0, 0.0],\n  [1.0, 0.0, 0.0, 0.0],\n  [0.5, 0.0, 0.0, 0.5],\n  [0.5, 0.0, 0.0, 0.5]],\n [[0.5, 0.5, 0.0, 0.0],\n  [0.5, 0.5, 0.0, 0.0],\n  [0.5, 0.5, 0.0, 0.0],\n  [0.5, 0.5, 0.0, 0.0],\n  [0.5, 0.5, 0.0, 0.0],\n  [0.5, 0.5, 0.0, 0.0],\n  [0.5, 0.5, 0.0, 0.0],\n  [1.0, 0.0, 0.0, 0.0],\n  [0.5, 0.0, 0.0, 0.5],\n  [0.5, 0.0, 0.0, 0.5]]]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "agt.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}